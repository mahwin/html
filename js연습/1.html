<html>
<head>
    <script src="./bundle.js"></script> 
</head>

<body>
    <input type=checkbox id="chk-hear-mic"><label for="chk-hear-mic">마이크 소리 듣기</label>
    <button id="record">녹음</button>
    <button id="stop">정지</button>
    <div id="sound-clips"></div>

    <script>   
        // 녹음
        let audioURL 
        const record = document.getElementById("record")
        const stop = document.getElementById("stop")
        const soundClips = document.getElementById("sound-clips")
        const chkHearMic = document.getElementById("chk-hear-mic")
        const audioCtx = new(window.AudioContext || window.webkitAudioContext)() 
        const analyser = audioCtx.createAnalyser()
        
        // naver stt
        
        
        const clientId = 'yhe9dnxsxf'; 
        const clientSecret = 'Rq0a26ULyvDa5uSbjf5swsugLmE7QK5DnL7Nkl2d'; 


        function makeSound(stream) {
            const source = audioCtx.createMediaStreamSource(stream)

            source.connect(analyser)
            //            analyser.connect(distortion)
            //            distortion.connect(biquadFilter)
            //            biquadFilter.connect(gainNode)
            //            gainNode.connect(audioCtx.destination) // connecting the different audio graph nodes together
            analyser.connect(audioCtx.destination)

        }

        if (navigator.mediaDevices) {
            console.log('getUserMedia supported.')

            const constraints = {
                audio: true
            }
            let chunks = []

            navigator.mediaDevices.getUserMedia(constraints)
                .then(stream => {

                    const mediaRecorder = new MediaRecorder(stream)
                    
                    chkHearMic.onchange = e => {
                        if(e.target.checked == true) {
                            audioCtx.resume()
                            makeSound(stream)
                        } else {
                            audioCtx.suspend()
                        }
                    }
                    
                    record.onclick = () => {
                        mediaRecorder.start()
                        record.style.background='yello'

                        setTimeout(function() {
                            mediaRecorder.stop()     
                        },3000);
                    }
                        
                        mediaRecorder.onstop = e =>{
                            console.log('데아터 저장중')
                        
                            const blob = new Blob(chunks, {
                                'type': 'audio/ogg codecs=opus'
                            })
                            console.log(chunks)
                            chunks = []
                            audioURL = URL.createObjectURL(blob)

                            const a = stt('Kor',audioURL)
                            console.log(a)
                            
                            

                            
                        }             
                        mediaRecorder.ondataavailable = e =>{
                           chunks.push(e.data)        
                        }
                    
                })
        
                  
        }

  
  function stt(language, filePath) {
        const url = `https://naveropenapi.apigw.ntruss.com/recog/v1/stt?lang=Kor`;
        const requestConfig = {
        url: url, 
        method: 'POST',
        headers: { 
            'Content-Type': 'application/octet-stream', 
            'X-NCP-APIGW-API-KEY-ID': clientId, 
            'X-NCP-APIGW-API-KEY': clientSecret 
        }, 
        body: fs.createReadStream(filePath) 
    }; 

    request(requestConfig, (err, response, body) => { 
        if (err) { 
            console.log(err); 
            return; 
            } 
            
            console.log(response.statusCode); 
            console.log(body); 
            }); 
        } 
        


        
  </script>
</body>
</html>